console.log("üß™ TESTANDO MODELO GROQ ATUALIZADO...")
console.log("=".repeat(50))

const GROQ_API_KEY = "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"

async function testGroqModel() {
  try {
    console.log("üîë Testando modelo: llama-3.3-70b-versatile")

    const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${GROQ_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "llama-3.3-70b-versatile", // Modelo atualizado
        messages: [
          {
            role: "system",
            content: "Voc√™ √© Sofia, uma IA especializada em psicologia positiva.",
          },
          {
            role: "user",
            content: "Ol√°, meu nome √© Jo√£o",
          },
        ],
        temperature: 0.7,
        max_tokens: 200,
        stream: false,
      }),
    })

    console.log(`üì° Status da resposta: ${response.status}`)

    if (!response.ok) {
      const errorText = await response.text()
      console.error(`‚ùå Erro: ${response.status} - ${errorText}`)
      return false
    }

    const data = await response.json()
    const message = data.choices?.[0]?.message?.content

    if (message) {
      console.log("‚úÖ MODELO FUNCIONANDO!")
      console.log("üìù Resposta:", message.substring(0, 100) + "...")
      console.log("üéØ Modelo:", data.model)
      console.log("üìä Uso:", data.usage)
      return true
    } else {
      console.error("‚ùå Resposta vazia")
      return false
    }
  } catch (error) {
    console.error("‚ùå Erro na requisi√ß√£o:", error.message)
    return false
  }
}

// Executar teste
testGroqModel().then((success) => {
  if (success) {
    console.log("\n‚úÖ CHAT FUNCIONAR√Å CORRETAMENTE!")
  } else {
    console.log("\n‚ùå PROBLEMA IDENTIFICADO - VERIFICAR CONFIGURA√á√ïES")
  }
})
